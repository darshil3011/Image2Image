{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark removal using PridNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:47:46.073180Z",
     "iopub.status.busy": "2022-06-02T07:47:46.072814Z",
     "iopub.status.idle": "2022-06-02T07:47:46.080348Z",
     "shell.execute_reply": "2022-06-02T07:47:46.078852Z",
     "shell.execute_reply.started": "2022-06-02T07:47:46.073151Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "import cv2\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, GlobalAveragePooling2D, AveragePooling2D, MaxPool2D, \n",
    "                                    UpSampling2D,BatchNormalization, Activation, Flatten, Dense, Input,\n",
    "                                    Add, Multiply, Concatenate, concatenate, Softmax\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import softmax\n",
    "from keras.callbacks import EarlyStopping\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:01.418888Z",
     "iopub.status.busy": "2022-06-02T07:48:01.418498Z",
     "iopub.status.idle": "2022-06-02T07:48:01.423583Z",
     "shell.execute_reply": "2022-06-02T07:48:01.422283Z",
     "shell.execute_reply.started": "2022-06-02T07:48:01.418854Z"
    }
   },
   "outputs": [],
   "source": [
    "# fetching data from kaggle, if using own dataset - enter respective paths \n",
    "train_path = '/kaggle/input/watermarked-not-watermarked-images/wm-nowm/train' # training directory\n",
    "valid_path = '/kaggle/input/watermarked-not-watermarked-images/wm-nowm/valid' # validation directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "This data preprocessing is done as per kaggle dataset I have used, this pipeline changes with respect to your dataset format and file structrure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:03.035783Z",
     "iopub.status.busy": "2022-06-02T07:48:03.035214Z",
     "iopub.status.idle": "2022-06-02T07:48:03.040256Z",
     "shell.execute_reply": "2022-06-02T07:48:03.039506Z",
     "shell.execute_reply.started": "2022-06-02T07:48:03.035732Z"
    }
   },
   "outputs": [],
   "source": [
    "def takeFileName(filedir): # remove just file name from directory and return\n",
    "    filename = np.array(filedir.split('/'))[-1] # take out the name, then return the name\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:04.352554Z",
     "iopub.status.busy": "2022-06-02T07:48:04.351979Z",
     "iopub.status.idle": "2022-06-02T07:48:04.361631Z",
     "shell.execute_reply": "2022-06-02T07:48:04.360481Z",
     "shell.execute_reply.started": "2022-06-02T07:48:04.352511Z"
    }
   },
   "outputs": [],
   "source": [
    "def matchFileNames(watermarkedarr, nonwatermarkedarr, dname_wm, dname_nwm):\n",
    "    sortedwmarr = np.array([])\n",
    "    sortednwmarr = np.array([])\n",
    "    \n",
    "    wmarr = list(watermarkedarr)\n",
    "    nwmarr = list(nonwatermarkedarr)\n",
    "    \n",
    "    length = len(watermarkedarr) if len(watermarkedarr) >= len(nonwatermarkedarr) else len(nonwatermarkedarr)\n",
    "    \n",
    "    for pos in range(length):\n",
    "        try:\n",
    "            if length == len(watermarkedarr): # more images in watermarked array\n",
    "                exist_nwm = nwmarr.index(wmarr[pos])\n",
    "                sortedwmarr = np.append(sortedwmarr, dname_wm + watermarkedarr[pos]) # this is the iterable\n",
    "                sortednwmarr = np.append(sortednwmarr, dname_nwm + nonwatermarkedarr[exist_nwm]) # this is the match\n",
    "            elif length == len(nonwatermarkedarr): # more images in nonwatermarked array\n",
    "                exist_wm = wmarr.index(nwmarr[pos])\n",
    "                sortedwmarr = np.append(sortedwmarr, dname_wm + watermarkedarr[exist_wm]) # this is the match\n",
    "                sortednwmarr = np.append(sortednwmarr, dname_nwm + nonwatermarkedarr[pos]) # this is the iterable\n",
    "        except ValueError: \n",
    "            continue\n",
    "    return sortedwmarr, sortednwmarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:05.579253Z",
     "iopub.status.busy": "2022-06-02T07:48:05.578752Z",
     "iopub.status.idle": "2022-06-02T07:48:21.956916Z",
     "shell.execute_reply": "2022-06-02T07:48:21.955453Z",
     "shell.execute_reply.started": "2022-06-02T07:48:05.579221Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sort the watermarked and non watermarked images into parallel arrays so NN will use it better\n",
    "\n",
    "train_path_watermarked_images = '../input/watermarked-not-watermarked-images/wm-nowm/train/watermark/'\n",
    "train_path_nonwatermarked_images = '../input/watermarked-not-watermarked-images/wm-nowm/train/no-watermark/'\n",
    "\n",
    "tp_watermarked = np.array([]) # array with watermarked image names\n",
    "tp_nonwatermarked = np.array([]) # array with nonwatermarked image names\n",
    "\n",
    "for root, dirs, files in os.walk(train_path_watermarked_images, topdown=True): # data length = 12510\n",
    "    for file in files:\n",
    "        tp_watermarked = np.append(tp_watermarked, takeFileName(file)) # append just the name of the file into array\n",
    "    \n",
    "for root, dirs, files in os.walk(train_path_nonwatermarked_images, topdown=True): # data length = 12477\n",
    "    for file in files:\n",
    "        tp_nonwatermarked = np.append(tp_nonwatermarked, takeFileName(file)) # append just the name of the file into array\n",
    "        \n",
    "tp_watermarked_sorted, tp_nonwatermarked_sorted = matchFileNames(tp_watermarked, tp_nonwatermarked, train_path_watermarked_images, train_path_nonwatermarked_images)\n",
    "\n",
    "\n",
    "valid_path_watermarked_images = '../input/watermarked-not-watermarked-images/wm-nowm/valid/watermark/'\n",
    "valid_path_nonwatermarked_images = '../input/watermarked-not-watermarked-images/wm-nowm/valid/no-watermark/'\n",
    "\n",
    "vp_watermarked = np.array([]) # array with watermarked image names\n",
    "vp_nonwatermarked = np.array([]) # array with nonwatermarked image names\n",
    "\n",
    "for root, dirs, files in os.walk(valid_path_watermarked_images, topdown=True): # data length = 3299\n",
    "    for file in files:\n",
    "        vp_watermarked = np.append(vp_watermarked, takeFileName(file)) # append just the name of the file into array\n",
    "    \n",
    "for root, dirs, files in os.walk(valid_path_nonwatermarked_images, topdown=True): # data length = 3289\n",
    "    for file in files:\n",
    "        vp_nonwatermarked = np.append(vp_nonwatermarked, takeFileName(file)) # append just the name of the file into array\n",
    "        \n",
    "vp_watermarked_sorted, vp_nonwatermarked_sorted = matchFileNames(vp_watermarked, vp_nonwatermarked, valid_path_watermarked_images, valid_path_nonwatermarked_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:21.959915Z",
     "iopub.status.busy": "2022-06-02T07:48:21.959254Z",
     "iopub.status.idle": "2022-06-02T07:48:37.273301Z",
     "shell.execute_reply": "2022-06-02T07:48:37.272445Z",
     "shell.execute_reply.started": "2022-06-02T07:48:21.959865Z"
    }
   },
   "outputs": [],
   "source": [
    "# dimension to resize to \n",
    "width = 256 # only certain dimensions work due to UpSampling (196x196 works, 148x148 works)\n",
    "height = 256\n",
    "dim = (width, height) # set the dimensions\n",
    "\n",
    "def createPixelArr(files):\n",
    "    data = []\n",
    "    for image in files:\n",
    "        try: # take each image and use imread to get the pixel values in a matrix \n",
    "            img_arr = cv2.imread(image, cv2.IMREAD_COLOR)\n",
    "            resized_arr = cv2.resize(img_arr, (width, height)) # rescale the image so every image is of the same dimension\n",
    "            data.append(resized_arr) # add the matrix of pixel values \n",
    "        except Exception as e:\n",
    "            print(e) # some error thrown in imread or resize\n",
    "    return np.array(data)\n",
    "\n",
    "train_wms_pixVals = createPixelArr(tp_watermarked_sorted)\n",
    "train_nwms_pixVals = createPixelArr(tp_nonwatermarked_sorted)\n",
    "\n",
    "val_wms_pixVals = createPixelArr(vp_watermarked_sorted)\n",
    "val_nwms_pixVals = createPixelArr(vp_nonwatermarked_sorted) # make ndarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation \n",
    "\n",
    "This step should remain same as once you have converted your images to collection of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:37.283773Z",
     "iopub.status.busy": "2022-06-02T07:48:37.283237Z",
     "iopub.status.idle": "2022-06-02T07:48:37.743697Z",
     "shell.execute_reply": "2022-06-02T07:48:37.742791Z",
     "shell.execute_reply.started": "2022-06-02T07:48:37.283739Z"
    }
   },
   "outputs": [],
   "source": [
    "# train test split to divide the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_wms_pixVals, train_nwms_pixVals, train_size=0.8, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:37.754995Z",
     "iopub.status.busy": "2022-06-02T07:48:37.754676Z",
     "iopub.status.idle": "2022-06-02T07:48:40.099991Z",
     "shell.execute_reply": "2022-06-02T07:48:40.098484Z",
     "shell.execute_reply.started": "2022-06-02T07:48:37.754968Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualise train test data to make sure we performed above steps correctly\n",
    "plt.figure(figsize=(25,25))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(cv2.cvtColor(X_test[i], cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:40.109145Z",
     "iopub.status.busy": "2022-06-02T07:48:40.108851Z",
     "iopub.status.idle": "2022-06-02T07:48:40.236211Z",
     "shell.execute_reply": "2022-06-02T07:48:40.235115Z",
     "shell.execute_reply.started": "2022-06-02T07:48:40.109116Z"
    }
   },
   "outputs": [],
   "source": [
    "# forcefully convert x_train and y_train into numpy array \n",
    "x = np.array(X_train)\n",
    "y = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN based Encoder Decoder \n",
    "You can choose to train this model or directly fast-forward to PridNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_width, img_height):\n",
    "\n",
    "    x = Input(shape=(img_width, img_height, 3))\n",
    "     \n",
    "    # Encoder - compresses the input into a latent representation\n",
    "    e_conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    pool1 = MaxPooling2D((2, 2), padding='same')(e_conv1)\n",
    "    batchnorm_1 = BatchNormalization()(pool1)\n",
    "    \n",
    "    e_conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(batchnorm_1)\n",
    "    pool2 = MaxPooling2D((2, 2), padding='same')(e_conv2)\n",
    "    batchnorm_2 = BatchNormalization()(pool2)\n",
    "    \n",
    "    e_conv3 = Conv2D(16, (3, 3), activation='relu', padding='same')(batchnorm_2)\n",
    "    h = MaxPooling2D((2, 2), padding='same')(e_conv3)\n",
    "    \n",
    "    # Decoder - reconstructs the input from a latent representation \n",
    "    d_conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(h)\n",
    "    up1 = UpSampling2D((2, 2))(d_conv1)\n",
    "    \n",
    "    d_conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1)\n",
    "    up2 = UpSampling2D((2, 2))(d_conv2)\n",
    "    \n",
    "    d_conv3 = Conv2D(16, (3, 3), activation='relu')(up2)\n",
    "    up3 = UpSampling2D((2, 2))(d_conv3)\n",
    "    \n",
    "    r = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(up3)\n",
    "    \n",
    "    model = Model(x, r)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark_auto_encoder = create_model(width, height)\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "history = watermark_auto_encoder.fit(X_train, y_train, batch_size=20, epochs=100, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRIDNet Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:40.246808Z",
     "iopub.status.busy": "2022-06-02T07:48:40.246456Z",
     "iopub.status.idle": "2022-06-02T07:48:40.260013Z",
     "shell.execute_reply": "2022-06-02T07:48:40.259103Z",
     "shell.execute_reply.started": "2022-06-02T07:48:40.246761Z"
    }
   },
   "outputs": [],
   "source": [
    "class Convolutional_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same')\n",
    "        self.conv_2 = Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same')\n",
    "        self.conv_3 = Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same')\n",
    "        self.conv_4 = Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same')\n",
    "\n",
    "    def call(self, X):\n",
    "        X_1 = self.conv_1(X)\n",
    "        X_1 = Activation('relu')(X_1)\n",
    "\n",
    "        X_2 = self.conv_2(X_1)\n",
    "        X_2 = Activation('relu')(X_2)\n",
    "\n",
    "        X_3 = self.conv_3(X_2)\n",
    "        X_3 = Activation('relu')(X_3)\n",
    "\n",
    "        X_4 = self.conv_4(X_3)\n",
    "        X_4 = Activation('relu')(X_4)\n",
    "        \n",
    "        #print('---conv block=',X_4.shape)\n",
    "        \n",
    "        return X_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:40.261507Z",
     "iopub.status.busy": "2022-06-02T07:48:40.261066Z",
     "iopub.status.idle": "2022-06-02T07:48:40.271987Z",
     "shell.execute_reply": "2022-06-02T07:48:40.271152Z",
     "shell.execute_reply.started": "2022-06-02T07:48:40.261471Z"
    }
   },
   "outputs": [],
   "source": [
    "class Channel_attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, C=64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.C=C\n",
    "        self.gap = GlobalAveragePooling2D()\n",
    "        self.dense_middle = Dense(units=2, activation='relu')\n",
    "        self.dense_sigmoid = Dense(units=self.C, activation='sigmoid')\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'C': self.C\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, X):\n",
    "        v = self.gap(X)\n",
    "        #print(\"ca_ after gap =\",v.shape)\n",
    "        fc1 = self.dense_middle(v)\n",
    "        #print(\"ca_ after fc1 =\",fc1.shape)\n",
    "        mu = self.dense_sigmoid(fc1)\n",
    "        #print(\"ca_ after fc2 =\",mu.shape)\n",
    "\n",
    "        U_out = Multiply()([X, mu])\n",
    "        \n",
    "        #print('---channel attention block=',U_out.shape)\n",
    "\n",
    "        return U_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:40.273723Z",
     "iopub.status.busy": "2022-06-02T07:48:40.273183Z",
     "iopub.status.idle": "2022-06-02T07:48:40.306506Z",
     "shell.execute_reply": "2022-06-02T07:48:40.305401Z",
     "shell.execute_reply.started": "2022-06-02T07:48:40.273679Z"
    }
   },
   "outputs": [],
   "source": [
    "class Avg_pool_Unet_Upsample_msfe(tf.keras.layers.Layer):\n",
    "    def __init__(self, avg_pool_size, upsample_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # ---initialization for Avg pooling---\n",
    "        self.avg_pool = AveragePooling2D(pool_size=avg_pool_size, padding='same')\n",
    "\n",
    "        # --- initialization for Unet---\n",
    "        self.deconv_lst = []\n",
    "        filter=512\n",
    "        for i in range(4):\n",
    "            self.deconv_lst.append(Conv2DTranspose(filters=filter/2, kernel_size=[3, 3], strides=2, padding='same'))\n",
    "            filter/=2\n",
    "\n",
    "        self.conv_32_down_lst = []\n",
    "        for i in range(4):\n",
    "            self.conv_32_down_lst.append(Conv2D(filters=64, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "        self.conv_64_down_lst = []\n",
    "        for i in range(4):\n",
    "            self.conv_64_down_lst.append(Conv2D(filters=128, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "        self.conv_128_down_lst = []\n",
    "        for i in range(4):\n",
    "            self.conv_128_down_lst.append(Conv2D(filters=256, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "        self.conv_256_down_lst = []\n",
    "        for i in range(4):\n",
    "            self.conv_256_down_lst.append(Conv2D(filters=512, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "        self.conv_512_down_lst = []\n",
    "        for i in range(4):\n",
    "            self.conv_512_down_lst.append(Conv2D(filters=1024, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "\n",
    "        self.conv_32_up_lst = []\n",
    "        for i in range(3):\n",
    "            self.conv_32_up_lst.append(Conv2D(filters=64, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "        self.conv_64_up_lst = []\n",
    "        for i in range(3):\n",
    "            self.conv_64_up_lst.append(Conv2D(filters=128, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "        self.conv_128_up_lst = []\n",
    "        for i in range(3):\n",
    "            self.conv_128_up_lst.append(Conv2D(filters=256, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "        self.conv_256_up_lst = []\n",
    "        for i in range(3):\n",
    "            self.conv_256_up_lst.append(Conv2D(filters=512, kernel_size=[3, 3], activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "\n",
    "        self.conv_3 = Conv2D(filters=3, kernel_size=[1, 1])\n",
    "\n",
    "        self.pooling1_unet = MaxPool2D(pool_size=[2, 2], padding='same')\n",
    "        self.pooling2_unet = MaxPool2D(pool_size=[2, 2], padding='same')\n",
    "        self.pooling3_unet = MaxPool2D(pool_size=[2, 2], padding='same')\n",
    "        self.pooling4_unet = MaxPool2D(pool_size=[2, 2], padding='same')\n",
    "\n",
    "        # ---initialization for Upsampling---\n",
    "        self.upsample = UpSampling2D(upsample_rate, interpolation='bilinear')\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'avg_pool_size': self.avg_pool_size,\n",
    "            'upsample_rate':self.upsample_rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def upsample_and_concat(self, x1, x2, i):\n",
    "        deconv = self.deconv_lst[i](x1)\n",
    "        deconv_output = Concatenate()([deconv, x2])\n",
    "        return deconv_output\n",
    "\n",
    "    def unet(self, input):\n",
    "        # ---Unet downsampling---\n",
    "        conv1 = input\n",
    "        for c_32 in self.conv_32_down_lst:\n",
    "            conv1 = c_32(conv1)\n",
    "        pool1 = self.pooling1_unet(conv1)\n",
    "\n",
    "        conv2 = pool1\n",
    "        for c_64 in self.conv_64_down_lst:\n",
    "            conv2 = c_64(conv2)\n",
    "        pool2 = self.pooling2_unet(conv2)\n",
    "\n",
    "        conv3 = pool2\n",
    "        for c_128 in self.conv_128_down_lst:\n",
    "            conv3 = c_128(conv3)\n",
    "        pool3 = self.pooling3_unet(conv3)\n",
    "\n",
    "        conv4 = pool3\n",
    "        for c_256 in self.conv_256_down_lst:\n",
    "            conv4 = c_256(conv4)\n",
    "        pool4 = self.pooling4_unet(conv4)\n",
    "\n",
    "        conv5 = pool4\n",
    "        for c_512 in self.conv_512_down_lst:\n",
    "            conv5 = c_512(conv5)\n",
    "\n",
    "        # ---Unet upsampling---\n",
    "        up6 = self.upsample_and_concat(conv5, conv4, 0)\n",
    "        conv6 = up6\n",
    "        for c_256 in self.conv_256_up_lst:\n",
    "            conv6 = c_256(conv6)\n",
    "\n",
    "        up7 = self.upsample_and_concat(conv6, conv3, 1)\n",
    "        conv7 = up7\n",
    "        for c_128 in self.conv_128_up_lst:\n",
    "            conv7 = c_128(conv7)\n",
    "\n",
    "        up8 = self.upsample_and_concat(conv7, conv2, 2)\n",
    "        conv8 = up8\n",
    "        for c_64 in self.conv_64_up_lst:\n",
    "            conv8 = c_64(conv8)\n",
    "\n",
    "        up9 = self.upsample_and_concat(conv8, conv1, 3)\n",
    "        conv9 = up9\n",
    "        for c_32 in self.conv_32_up_lst:\n",
    "            conv9 = c_32(conv9)\n",
    "\n",
    "        conv10 = self.conv_3(conv9)\n",
    "        return conv10\n",
    "\n",
    "    def call(self, X):\n",
    "        avg_pool = self.avg_pool(X)\n",
    "        #print(\"ap =\",avg_pool.shape)\n",
    "        unet = self.unet(avg_pool)\n",
    "        upsample = self.upsample(unet)\n",
    "        return upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:40.308459Z",
     "iopub.status.busy": "2022-06-02T07:48:40.308096Z",
     "iopub.status.idle": "2022-06-02T07:48:40.319350Z",
     "shell.execute_reply": "2022-06-02T07:48:40.318083Z",
     "shell.execute_reply.started": "2022-06-02T07:48:40.308419Z"
    }
   },
   "outputs": [],
   "source": [
    "class Multi_scale_feature_extraction(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.msfe_16 = Avg_pool_Unet_Upsample_msfe(avg_pool_size=16, upsample_rate=16)\n",
    "        self.msfe_8 = Avg_pool_Unet_Upsample_msfe(avg_pool_size=8, upsample_rate=8)\n",
    "        self.msfe_4 = Avg_pool_Unet_Upsample_msfe(avg_pool_size=4, upsample_rate=4)\n",
    "        self.msfe_2 = Avg_pool_Unet_Upsample_msfe(avg_pool_size=2, upsample_rate=2)\n",
    "        self.msfe_1 = Avg_pool_Unet_Upsample_msfe(avg_pool_size=1, upsample_rate=1)\n",
    "\n",
    "    def call(self, X):\n",
    "        up_sample_16 = self.msfe_16(X)\n",
    "        up_sample_8 = self.msfe_8(X)\n",
    "        up_sample_4 = self.msfe_4(X)\n",
    "        up_sample_2 = self.msfe_2(X)\n",
    "        up_sample_1 = self.msfe_1(X)\n",
    "        msfe_out = Concatenate()([X, up_sample_16, up_sample_8, up_sample_4, up_sample_2, up_sample_1])\n",
    "\n",
    "        return msfe_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:40.321125Z",
     "iopub.status.busy": "2022-06-02T07:48:40.320634Z",
     "iopub.status.idle": "2022-06-02T07:48:40.337723Z",
     "shell.execute_reply": "2022-06-02T07:48:40.336817Z",
     "shell.execute_reply.started": "2022-06-02T07:48:40.321075Z"
    }
   },
   "outputs": [],
   "source": [
    "class Kernel_selecting_module(tf.keras.layers.Layer):\n",
    "    def __init__(self, C=21, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.C = C\n",
    "        self.c_3 = Conv2D(filters=self.C, kernel_size=(3,3), strides=1, padding='same', kernel_regularizer=regularizers.l2(0.001))\n",
    "        self.c_5 = Conv2D(filters=self.C, kernel_size=(5,5), strides=1, padding='same', kernel_regularizer=regularizers.l2(0.001))\n",
    "        self.c_7 = Conv2D(filters=self.C, kernel_size=(7,7), strides=1, padding='same', kernel_regularizer=regularizers.l2(0.001))\n",
    "        self.gap = GlobalAveragePooling2D()\n",
    "        self.dense_two = Dense(units=2, activation='relu')\n",
    "        self.dense_c1 = Dense(units=self.C)\n",
    "        self.dense_c2 = Dense(units=self.C)\n",
    "        self.dense_c3 = Dense(units=self.C)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'C': self.C\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, X):\n",
    "        X_1 = self.c_3(X)\n",
    "        X_2 = self.c_5(X)\n",
    "        X_3 = self.c_7(X)\n",
    "\n",
    "        X_dash = Add()([X_1, X_2, X_3])\n",
    "\n",
    "        v_gap = self.gap(X_dash)\n",
    "        v_gap = tf.reshape(v_gap, [-1, 1, 1, self.C])\n",
    "        fc1 = self.dense_two(v_gap)\n",
    "\n",
    "        alpha = self.dense_c1(fc1)\n",
    "        beta = self.dense_c2(fc1)\n",
    "        gamma = self.dense_c3(fc1)\n",
    "\n",
    "        before_softmax = concatenate([alpha, beta, gamma], 1)\n",
    "\n",
    "        after_softmax = softmax(before_softmax, axis=1)\n",
    "        a1 = after_softmax[:, 0, :, :]\n",
    "\n",
    "        a1 = tf.reshape(a1, [-1, 1, 1, self.C])\n",
    "\n",
    "        a2 = after_softmax[:, 1, :, :]\n",
    "        a2 = tf.reshape(a2, [-1, 1, 1, self.C])\n",
    "        a3 = after_softmax[:, 2, :, :]\n",
    "        a3 = tf.reshape(a3, [-1, 1, 1, self.C])\n",
    "\n",
    "        select_1 = Multiply()([X_1, a1])\n",
    "        select_2 = Multiply()([X_2, a2])\n",
    "        select_3 = Multiply()([X_3, a3])\n",
    "\n",
    "        out = Add()([select_1, select_2, select_3])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:40.339517Z",
     "iopub.status.busy": "2022-06-02T07:48:40.339045Z",
     "iopub.status.idle": "2022-06-02T07:48:44.020226Z",
     "shell.execute_reply": "2022-06-02T07:48:44.018155Z",
     "shell.execute_reply.started": "2022-06-02T07:48:40.339481Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    #tf.keras.backend.clear_session()\n",
    "\n",
    "    input = Input(shape=(256,256,3), name=\"input_layer\")\n",
    "\n",
    "    conv_block = Convolutional_block()(input)\n",
    "    ca_block = Channel_attention()(conv_block)\n",
    "    ca_block = Conv2D(filters=3, kernel_size=(3,3), strides=1, padding='same')(ca_block)\n",
    "    ca_block = Concatenate()([input, ca_block])\n",
    "\n",
    "    msfe_block = Multi_scale_feature_extraction()(ca_block)\n",
    "\n",
    "    ksm = Kernel_selecting_module()(msfe_block)\n",
    "    ksm = Conv2D(filters=3, kernel_size=(3,3), strides=1, padding='same')(ksm)\n",
    "    model = Model(inputs=[input], outputs=[ksm])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear RAM\n",
    "This step is necessary to make space in RAM so that while model training, your system does not run out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T07:48:44.022482Z",
     "iopub.status.busy": "2022-06-02T07:48:44.022147Z",
     "iopub.status.idle": "2022-06-02T07:48:44.354956Z",
     "shell.execute_reply": "2022-06-02T07:48:44.353906Z",
     "shell.execute_reply.started": "2022-06-02T07:48:44.022449Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "X_train = 0\n",
    "y_train = 0\n",
    "train_wms_pixVals = 0 \n",
    "train_nwms_pixVals = 0 \n",
    "val_wms_pixVals = 0 \n",
    "val_nwms_pixVals = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "you can modify batch size and steps per epoch based on the computation resources available to you. However it is recommended to keep lower batch size since our model is computationally heavy in terms of trainable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T08:21:43.308026Z",
     "iopub.status.busy": "2022-06-02T08:21:43.307388Z",
     "iopub.status.idle": "2022-06-02T09:37:09.984295Z",
     "shell.execute_reply": "2022-06-02T09:37:09.983445Z",
     "shell.execute_reply.started": "2022-06-02T08:21:43.307961Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=Adam(learning_rate=0.0009))\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "model.fit(x, y, batch_size = 2, steps_per_epoch = 50, epochs = 5, verbose = 1, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T09:46:16.532572Z",
     "iopub.status.busy": "2022-06-02T09:46:16.532035Z",
     "iopub.status.idle": "2022-06-02T09:46:16.542189Z",
     "shell.execute_reply": "2022-06-02T09:46:16.541041Z",
     "shell.execute_reply.started": "2022-06-02T09:46:16.532531Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference_single_image(model, noisy_image):\n",
    "    input_image = np.expand_dims(noisy_image, axis=0)\n",
    "    predicted_image = model.predict(input_image)\n",
    "    \n",
    "    return predicted_image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-02T09:46:21.589345Z",
     "iopub.status.busy": "2022-06-02T09:46:21.588974Z",
     "iopub.status.idle": "2022-06-02T09:46:21.597089Z",
     "shell.execute_reply": "2022-06-02T09:46:21.596262Z",
     "shell.execute_reply.started": "2022-06-02T09:46:21.589300Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(model, xtest, n):\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        noisy_image = xtest[i]\n",
    "        predicted_image = inference_single_image(model, xtest[i])\n",
    "        predicted_image/=255\n",
    "        \n",
    "        print(predicted_image.shape)\n",
    "\n",
    "        f, axarr = plt.subplots(1,2, figsize=(21,21))\n",
    "        axarr[0].imshow(noisy_image)\n",
    "        axarr[0].set_title(\"Noisy image\")\n",
    "        axarr[0].set_axis_off()\n",
    "        axarr[1].imshow(predicted_image)\n",
    "        axarr[1].set_title(\"Predicted image\")\n",
    "        axarr[1].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model, X_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
